 第1章 绪论

 1.1 数据科学的概念【对应教材1.1】

 1.1.1 数据科学的研究对象

 1.1.2 常见的数据科学方法

 有监督学习：数据中同时包含特征变量和响应变量

 无监督学习：数据中只有特征变量，没有响应变量

 半监督学习：当数据中同时存在大量没有标签的样本以及少量有标签的样本时，需要使用

 1.1.3 数据科学的应用领域【对应教材1.3】

 1. 互联网行业

 2. 零售行业

 3. 金融行业

 4. 医疗健康行业

***

 1.2 数据科学的发展变迁【对应教材1.2】

 1.2.1 数据科学的前身：统计学

 1. 古典记录统计学时期

 时间：17世纪中叶开始

 背景：随着欧洲资本主义兴起，政治改革家们对经济数据进行科学管理的需求日益增加。一系列统计学的奠基性工作在欧洲各国展开。

 代表人物：

 William Petty（威廉·配第），贡献：

 Gottfried Achenwall（戈特弗里德·阿亨瓦尔），贡献：

 Pascal（帕斯卡）和Fermat（费马），贡献：

 Bayes（贝叶斯），贡献：

 2. 近代描述统计学时期

 时间：18世纪末到19世纪末

 背景：随着欧洲各国先后完成工业革命，各行业的数据资料积累达到一定规模，对统计的需求从国计民生延伸到科学技术的各个领域。

 代表人物：

 Moivre（棣莫弗），贡献：

 Laplace（拉普拉斯），贡献：

 Gauss（高斯），贡献：

 Quetelet（凯特勒），贡献：

 Pearson（皮尔逊），贡献：

 3. 现代推断统计学时期

 时间：20世纪

 背景：随着科学技术的快速发展，人类需要从各个学科中获取的大量数据中挖掘更多信息以指导未来的生产活动。统计学的重心转为推断性统计。

 代表人物：

 Gosset（哥赛特），贡献：

 Fisher（费雪），贡献：

 新方法的发展：

 20世纪30年代以来，现代医院统计方法------20世纪80年代以来，高维数据的处理和分析方法

 基于贝叶斯思想的统计方法：朴素贝叶斯分类器、贝叶斯网络、马尔科夫蒙特卡洛方法

***

 1.2.2 当代统计学：数据科学

 背景：20 世纪90 年代以来，随着互联网技术的迅速发展，如何从大样本中获取更丰富的有用信息就变得尤为重要。各个学科对于通过现有数据预测未来数据走向的需求也日益增长。数据科学的概念应运而生。

 1.2.3 统计学与数据科学的关系

 从统计学到数据科学的发展历程概览

 学术界的两种观点：

 统计学应该坚持自身原则，而不是与数据科学混为一谈。

 数据科学是对统计学的升华，后者应该向前者靠拢。

 教材的观点：

 经典统计学是数据科学的前身，而数据科学则是不断发展、与时俱进的当代统计学。

***

 1.3 数据科学的知识体系【仅有讲义、无教材】

 1.3.1 数据科学专业的建设背景

 1.3.2 数据科学专业人才的核心素养

 1. 一思维：分析思维

 2. 二基础：数学基础、算法和软件基础

 3. 三能力：数据管理能力、数据建模能力、数据价值的跨学科解读能力

 4. 数据科学专业的课程体系

 1.3.3 认识"数据科学家"

 1. 与数据工程师、数据分析师的区别

 2. 能力需求

***

 第2章 数据科学的编程工具

 2.1 数据科学编程工具概述【对应教材第2章导读部分】

 2.1.1 R语言

 基于S语言开发，用于统计分析、图形表示和报告的开源编程语言

 2.1.2 Python

 进入大数据时代，基于Python的各种机器学习和深度学习的工具包得到了爆发式增长，Python成为数据科学的主流语言。

 2.1.3 R语言与Python的区别

 R代表了统计学家的思维方式，专注于统计计算和可视化，在分析方法尤其是统计模型方面资源更丰富，其基础数据结构和矩阵运算方法也更符合分析师的习惯。

 Python代表了计算机编程思维方式，是一种通用工具，同时也包含丰富的数据分析资源。

***

 2.2 R语言入门【对应教材2.1】

 2.2.1 安装和设置

 1. Windows下安装

 2. Mac和Linux下安装

 3. 集成开发环境与RStudio

 集成开发环境（IDE）：方便进行编辑、调试、编译、执行、版本管理等工作

 RStudio：可以免费使用，是目前最受欢迎的R语言集成开发环境

***

 2.2.2 基础操作

 1. Hello World!

 2. 变量和赋值

 赋值符号有：

 3. 函数和操作符

 函数的形式：

 4. 文档与帮助

 查看帮助文档：用英文问号加上要查询的内容，例如：?log

 其他建议：

 学会使用搜索引擎，建议用英文查询

 求助于R语言的开源社区、论坛等

 5. 包的管理

 R包是把R函数、数据、预编译代码以一种定义完善的格式组织在一起的集合，用于拓展统计分析技能

 安装：在联网的环境下可以直接通过命令进行R包的在线安装，例如： install.packages("readxl")

 加载：在需要使用包的时候再导入，例如： library(readxl)

***

 2.2.3 数据结构

 1. 数值类型和对象属性

 数值型数据（numeric）

 字符型数值（character）

 逻辑型数值（logical）：只包含两个值"TRUE"和"FALSE"

 因子型数值（factor）：是一个用于描述分类变量的自然数向量，对其中不重复的值打上了字符标签

 函数 factor() 可以基于向量构建因子

 函数 levels() 可以提取其中不重复的标签

 2. 向量

 是所有其他数据对象的基础，可以说是R语言的最基础结构

 创建向量：y \<- c(2, 5, 7, 1, 9, 4.5); z \<- rep("A", 6)

 用函数 length() 来获取向量的长度

 使用符号 "\[\]" 可以进行取子集的操作

 3. 矩阵和数组

 矩阵：

 函数 matrix 定义矩阵： A1 = matrix(1:12, nrow =4, ncol =3)

 使用专门的操作符进行矩阵运算，例如矩阵乘法：A1 %\*% t(A1)

 数组：

 是矩阵的扩展，除了行列外还有其他的维度。函数 array 定义数组：a\<- array(1:24, dim = c(2, 3, 4))

 4. 列表

 其元素可以为任意数据类型，甚至是其他列表。使用函数 list 来创建列表：l1 \<- list(x1, x2 , A1)

 符号 "\[\[\]\]" 和 "\$"可以用来获取列表中的元素。

 5. 数据框

 通过函数 data.frame 来创建数据框：d1\<- data.frame(v1= x, v2 = z)

***

 2.2.4 基础语法

 1. 条件语句

 需要根据某些条件判断来执行某些分支代码。 使用 if 来进行判断，并结合 else 实现条件语句。

 2. 循环语句

 常用：for循环

 其他：while循环，repeat循环

***

 第3章 数据可视化

 3.1 可视化基础【对应教材5.1】

 3.1.1 可视化案例

 数据可视化的基础目标：用一种直观的方式来发现数据中隐藏的规律

 好的可视化作品的特征：直观，信息丰富

 正确理解数据可视化作品：应格外重视统计分析的研究假设

 3.1.2 图形设备

 R语言图形设备界面

 R 基础画图示例： plot(MSales \~ Comments, data = df2)

***

 3.1.3 基础作图

 1. 修改轴标签和图标题

 plot(MSales \~ Comments, data = df2, main = "Test", xlab= "X", ylab = "Y")

 2. 修改颜色和形状

 plot(MSales \~ Comments,data = df2\[1:20,\],col = "red",pch = 19,cex = 1)

 3. 修改线型

 plot(MSales \~ Comments,data = df2\[1:20,\], type = "l", lty = 2, lwd = 2,col = "red")

 4. 分组设置

 plot(MSales \~ Comments, data =df2\[df2\$Place %in% c("广东 广州", "浙江 杭州"),\]\[1:20,\],col = factor(Place),pch =19)

 5. 添加图例

 legend(0, 6, legend = c("广州", "杭州"), col = c(1, 2), pch = 19)

 6. 添加文字

 text(1, 2, expression(paste(mu, "=100, ", sigma, "=15")))

***

 3.1.4 ggplot绘图语言

 2005年，哈德利（Hadley Wickham）基于R语言创造了ggplot2，这是一个R包，也是第一次完美实现了TheGrammar of Graphics的载体。

 基础的作图元素包括：数据和映射关系、几何对象（点、线、多边形等）、统计变换（函数和模型）、坐标系（直角坐标、极坐标等）、分面（数据的层次结构）、标度（图形细节）

 代码示例：

 library(ggplot2)

 p \<- ggplot(mtcars, aes(x = mpg, y = wt))

 p \<- p + geom_point()

 p \<- p + geom_smooth(method ="loess")

 print(p)

***

 3.2 可视化与数据分析【对应教材5.2】

 3.2.1 单变量的分布

 定量变量：

 直方图，hist(df2\[\['MSales'\]\], breaks = 20,main = "", xlab ="")

 定性变量：

 条形图，dffreq \<- table(df3\[\['Place'\]\])；barplot(dffreq)

 饼图，pie(dffreq)

 3.2.2 两变量的关系

 两个定量变量：

 散点图，plot(MSales \~ Comments, data = df2)

 一个定量变量、一个定性变量：

 分组箱线图，boxplot(MSales \~ Place, data = df3)

 注意：箱线图的含义

 两个定性变量：

 马赛克图，df3\$Freq \<- 1tab3\<- xtabs(Freq \~ Protection+ Place, data = df3)；plot(tab3, main = "")

 3.2.3 多变量的关系

 相关系数矩阵图，library(corrplot)；corr1 \<- cor(d2)；corrplot(corr1)

***

 3.3 现代数据可视化方法【对应教材5.3】

 3.3.1 动态统计图形

 3.3.2 交互式工具

***

 第4章 数据挖掘和机器学习

 4.1 从海量数据到大数据【对应教材6.1】

 4.1.1海量数据与数据挖掘

 什么是数据挖掘？

 从大量的数据中通过算法挖掘出隐藏于其中信息的过程，一开始是为解决行业中海量数据的问题而生，其风格也比较偏业界，尤其是结合了很多数据库管理的技术。

 数据挖掘的6个步骤

 1. 问题理解，2. 数据理解，3. 数据准备，4. 数据建模，5. 模型评估，6. 模型部署

***

 4.1.2 大数据与机器学习

 什么是机器学习？

 如果一个计算机程序针对某类任务T的用P衡量的性能根据经验E来自我完善，那么我们称"这个计算机程序在从经验 E 中学习，针对某类任务 T，它的性能用 P 来衡量"。

 任务T的种类包括：分类、回归、聚类、异常检测，等等。

 性能的定量度量标准P，是特定于系统执行的任务T而言。例如分类任务，可以使用"准确率"（Accuracy）等指标进行度量。

 经验E是指从数据集中获取的经验。

***

 4.2 无监督学习【对应教材6.2】

 4.2.1 主成分分析

 当数据集的变量数很多的时候，使用该方法找到前几位的主成分，可以用来解释大量的变量，实现降维并更好地了解数据中的规律。

 用princomp()进行主成分分析

 4.2.2 聚类分析

 以类内差异最小化、类间差异最大化为目标。

 常见方法：

 1. 层次聚类：

 将不同距离程度的样本根据层次划分为树状结构。

 层次聚类从点的距离入手，遍历所有点，将距离最近的点与点、点与类、类与类连接在一起，形成树状的层次结构，如此反复迭代，直到汇集到一个点。

 其中的关键是：计算类与类（或者点与类）的距离

 2. K-means聚类

 如果聚类结果可以使用一组原型来描述，并通过对原型不断迭代来求解，就称为原型聚类（Prototype-based Clustering），例如K-Means聚类。

 需要先指定类的数目

 3. 密度聚类

 当类别结构无法使用原型来描述时，可以用样本的紧密程度来进行描述，称为密度聚类（Density-based Clustering）。最常见的是DBSCAN 算法

***

 4.3 有监督学习【对应教材6.3】

 4.3.1 回归分析

 有监督学习的数据样本中包含了标签的信息，如果标签对应的特征是连续变量，可以使用回归分析来研究标签和其他特征之间的关系。

 多元线性回归模型：Y=β_0+β_1 X_1+β_2 X_2+⋯+β_P X_p+ε

 R语言内置的stats包中包含了lm函数，是经典的线性回归模型求解工具，其分析结果的对象中包含了各种常见的统计量。

 对于一个完整的回归分析来说，研究者除了参数估计外，还需要对模型进行显著性检验（F检验）、对参数进行显著性检验（t检验），并诊断是否存在多重共线性、序列自相关性等。

***

 4.3.2 分类问题和分类性能评估

 如果标签对应的特征是离散变量，可以使用分类模型来研究标签和其他特征之间的关系。

 分类性能评估指标：

 准确度（Accurary）。表示真阳性和真阴性的数目除以所有预测值的个数，计算公式为：(真阳性+真阴性)/ 总数=(TP +TN) /N

 错误率（Error Rate）。表示不正确分类的比例，等于1 减去准确度。

 精度（Precision）。也称为查准率，表示真阳性在所有预测为阳性例子中的比例，计算公式为：真阳性/(真阳性+假阳性)=TP/(TP+FP)

 召回（Recall）。也称为查全率，表示真阳性与阳性总数的比例，计算公式为：真阳性/(真阳性+假阴性)=TP/(TP+FN)

 灵敏度（Sensitivity）。也称为真阳性比率，度量了阳性样本被正确分类的比例，和召回的含义相同，计算公式为：真阳性/(真阳性+假阴性)=TP/(TP+FN)

 特异性（Specificity）。也称为真阴性比率，度量了阴性样本被正确分类的比例，计算公式为：真阴性/(真阴性+假阳性)=TN/(TN+FP)

 Kappa 统计量。用来描述预测值和真实值之间一致的概率，可以消除一些因为完全偶然猜对的影响。0.6以上表示效果不错，0.8 以上表示效果很好。

 F1 分数。可以看作是模型精度和召回的一种调和平均，它的最大值是1，最小值是0，其值越高越好。

 ROC曲线是机器学习分类问题中最常用的结果评估图形。当某个模型的AUC很大，说明分类效果很好。

***

 4.3.3 常用分类模型

 1. 逻辑斯蒂回归

 计算性能和可解释性都很好。模型的自变量之间假设了线性关系，因此回归系数可以理解成权数，应用到具体的业务中时非常方便。

 log⁡(P∕(1-P) )=β_0+β_1 x+ε

 2. 决策树

 用树结构的方式来描述一个分类的过程。基于训练集数据学习划分规则，递归地建立树状模型。

***

 第5章 数据科学的综合实践

 5.1 统计建模【仅有讲义、无教材】

 5.1.1 统计建模概述

 定义：利用各种统计分析方法对数据建立统计模型和探索处理的过程，用于揭示数据背后的规律，诠释社会经济现象，或对经济和社会发展作出预测和判断。

 基本流程：建模前的准备，模型选择与建立，模型评价与解读

***

 5.1.2 建模前的准备

 1. 缺失值处理

 缺失值的表示方式：NA，-99，等等

 处理思路：先统计占比、分析原因，在选择恰当的方式予以处理

 处理方案：

 删除有缺失的样本

 优点：简单易操作

 缺点：损失样本

 缺失值插补

 常用方法：均值插补

 2. 异常值排查

 异常值的定义：若某个样本的观测值远高于或远低于其他大多数观测值，称其为异常值

 排查工具：箱线图

 处理方式：缩尾处理，截尾处理

 3. 数据标准化

 何时需要做标准化：各个特征变量的取值范围差异较大时

 具体公式：Z_i = (X_i - Xbar)/s_X

 标准化后的数据特点：均值为0、标准差为1

***

 5.1.3 模型选择与建立

 根据因变量Y的数据类型选择模型

 定量数据（收入、房价）：线性回归模型

 定性数据（申请贷款是否成功）：逻辑回归模型

 定序数据（对于产品的满意度）：定序回归模型

 计数数据（购买产品人数）：泊松回归模型

 按照是否有因变量选择模型：

 有监督模型

 因变量是定量数据：

 因变量是定性数据：

 其他情况

 无监督模型

 降维：

 聚类：

 5.1.4 模型评价与解读

 模型的评价

 模型的解读

***

 5.2 数据分析报告【仅有讲义、无教材】

 5.2.1 数据分析报告的定义

 5.2.2 数据分析报告的评价标准

 1. 清晰的逻辑

 结构完整：背景介绍、数据来源与说明、描述性分析、统计建模、结论与建议

 2. 规范的表达

 尊重图、表、公式等科学规范

 科学引用参考文献和资料来源

 3. 优雅的外观

 图文并茂

 详略得当
